{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenbeschreibung\n",
    "\n",
    "\n",
    "Im Rahmen unseres Projekts für Big Data haben sich die Teammitglieder Colin Sturm, Leonard Debinski, Daniel Gern, Tim Paschke, Yusuf Esentürk und Carlo Koppanyi zusammengeschlossen. Unser zentrales Forschungsthema ist die Kundensegmentierung und die Personalisierung von Marketingmaßnahmen. Um eine praxisnahe Herangehensweise zu gewährleisten, haben wir auf unserer Miro-Plattform drei detaillierte Personas entwickelt. Diese Personas reflektieren unterschiedliche Kundenprofile mit spezifischen Problemen und Bedürfnissen in Bezug auf unser Forschungsthema. Um diese Herausforderungen effektiv anzugehen, haben wir uns für die Analyse eines passenden Datensatzes entschieden, der darauf ausgerichtet ist, die Problematiken und Wünsche der Personas gezielt zu adressieren.\n",
    "Bei der Auswahl eines geeigneten Datensatzes für unser Projekt legen wir großen Wert darauf, hauptsächlich quantitative Merkmale und nur wenige qualitative Merkmale zu berücksichtigen. Nach sorgfältiger Prüfung verschiedener Optionen kamen wir zu dem Schluss, dass der \"Datensatz Online Shop Customer Sales Data\" am besten unseren Anforderungen entspricht. Der Datensatz beinhaltet verschiedene Merkmale zu Kunden eines Online-Shops. Das Merkmal \"Customer_id\" dient als eindeutige Identifikation für jeden Kunden. Das Alter des Kunden wird durch \"Age\" wiedergegeben. Das Geschlecht des Kunden ist unter \"Gender\" kategorisiert, wobei 0 für männlich und 1 für weiblich steht. \"Revenue_Total\" zeigt den Gesamtumsatz an, den ein Kunde bisher generiert hat, während \"N_Purchases\" die Anzahl seiner Käufe bis zum aktuellen Datum anzeigt. Das Datum des letzten Kaufs wird im Format dd.mm.yy unter \"Purchase_DATE\" erfasst und der Wert dieses letzten Kaufs in Euro wird unter \"Purchase_VALUE\" angezeigt. Das Merkmal \"Pay_Method\" gibt an, welche Zahlungsmethode der Kunde verwendet hat, wobei 0 für digitale Geldbörsen, 1 für Karten, 2 für PayPal und 3 für andere Zahlungsmethoden steht. \"Time_Spent\" zeigt die in Sekunden verbrachte Zeit des Kunden auf der Webseite. Der von dem Kunden verwendete Browser wird durch \"Browser\" kategorisiert, wobei 0 für Chrome, 1 für Safari, 2 für Edge und 3 für andere Browser steht. Zusätzlich zeigt \"Newsletter\", ob ein Kunde für den Newsletter angemeldet ist oder nicht, wobei 0 bedeutet, dass er nicht abonniert ist und 1, dass er abonniert ist. Schließlich gibt \"Voucher\" an, ob ein Kunde einen Gutschein verwendet hat, wobei 0 für nicht verwendet und 1 für verwendet steht. Zu erkennen sind sechs quantitative Merkmale und vier qualitative Merkmale. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliothekten\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenvorbereitung\n",
    "\n",
    "Es handelt sich bei der Datenvorbereitung um einen systematischen Prozess, die Datenqualität zu verbessern und die Genauigkeit der zukünftigen Analysen zu erhöhen.\n",
    "Es gibt verschiedene Methoden, um einen Datensatz auf eine bevorstehende Analyse vorzubereiten.\n",
    "\n",
    " \n",
    " Zunächst werden generelle Informationen zum Datensatz angezeigt. Diese sind wichtig, da am Ende des Bereinigungsprozeses geprüft werden muss, ob sich die quantitiven Informationen wie Zeilenanzahl geändert haben. Diese Informationen sind wichtig, da sie bei der Modellbildung verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65796 entries, 0 to 65795\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Customer_id     65796 non-null  int64  \n",
      " 1   Age             65796 non-null  int64  \n",
      " 2   Gender          65796 non-null  int64  \n",
      " 3   Revenue_Total   65796 non-null  float64\n",
      " 4   N_Purchases     65796 non-null  int64  \n",
      " 5   Purchase_DATE   65796 non-null  object \n",
      " 6   Purchase_VALUE  65796 non-null  float64\n",
      " 7   Pay_Method      65796 non-null  int64  \n",
      " 8   Time_Spent      65796 non-null  int64  \n",
      " 9   Browser         65796 non-null  int64  \n",
      " 10  Newsletter      65796 non-null  int64  \n",
      " 11  Voucher         65796 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(1)\n",
      "memory usage: 6.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Daten einlesen\n",
    "df = pd.read_csv('Online Shop Customer Sales Data.csv')\n",
    "\n",
    "# ausgeben der quantitativen Informationen zum Datensatz\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun gilt es zu prüfen, ob die Daten im richtigen Format vorliegen. Hierzu betrachten wir die Datentypen.\n",
    "Dies ist wichtig, da verschiedene Datentypen unterschiedliche statistische Analysen erfordern.\n",
    "\n",
    "astype(): Die Funktion ist ein nützliches Werkzeug in Pandas, das es ermöglicht, den Datentyp einer Spalte zu ändern.\n",
    "\n",
    "Zunächst müssen jedoch die einzelnen Datentypen der Spalten identifiziert werden. Hierzu wird folgende Funktion verwendet: \n",
    "print(df.info())\n",
    "\n",
    "Es ergibt, dass alle Datentypen korrekt identifiziert wurden. Eine Ausnahme bildet die Spalte „Purchase_DATE“. Um die Werte korrekt in ein gültiges Datumsformat zu packen Bedarf es 2 Schritte: \n",
    "\n",
    "1.\tPrüfen, ob ein unmögliches Datum enthalten ist\n",
    "2.\tDie Zeichenkette in ein einheitliches Format (dd.mm.yy) konvertieren\n",
    "Hierzu wird die strptime() Funktion aus dem datetime Modul in Python verwendet. Diese Funktion versucht, eine Zeichenkette in ein Datum zu konvertieren. Wenn die Zeichenkette kein gültiges Datum ist, wird ein ValueError ausgelöst.\n",
    "\n",
    "Ein Datum gilt als gültig, wenn es folgende Kriterien erfüllt:\n",
    "\n",
    "Format: Ein gültiges Datum sollte ein bestimmtes Format haben. In der Regel wird das Datum im Format 'Tag.Monat.Jahr' angegeben, wobei Tag, Monat und Jahr durch Punkte getrennt sind. \n",
    "Werte: Ein gültiges Datum sollte gültige Werte für Tag, Monat und Jahr haben. Beispielsweise sollte der Tag zwischen 1 und 31 liegen, der Monat zwischen 1 und 12 und das Jahr ein gültiges Jahr sein (z.B. 2023). Wenn eines dieser Kriterien nicht erfüllt ist, ist das Datum nicht gültig.\n",
    "Konsistenz: Ein gültiges Datum sollte konsistent sein. Beispielsweise sollte ein Datum im Format '30.02.2023' nicht gültig sein, da der Februar nicht 30 Tage hat. Wenn das Datum nicht konsistent ist, ist es nicht gültig.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65796 entries, 0 to 65795\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Customer_id     65796 non-null  int64  \n",
      " 1   Age             65796 non-null  int64  \n",
      " 2   Gender          65796 non-null  int64  \n",
      " 3   Revenue_Total   65796 non-null  float64\n",
      " 4   N_Purchases     65796 non-null  int64  \n",
      " 5   Purchase_DATE   65796 non-null  object \n",
      " 6   Purchase_VALUE  65796 non-null  float64\n",
      " 7   Pay_Method      65796 non-null  int64  \n",
      " 8   Time_Spent      65796 non-null  int64  \n",
      " 9   Browser         65796 non-null  int64  \n",
      " 10  Newsletter      65796 non-null  int64  \n",
      " 11  Voucher         65796 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(1)\n",
      "memory usage: 6.0+ MB\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65796 entries, 0 to 65795\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Customer_id     65796 non-null  int64         \n",
      " 1   Age             65796 non-null  int64         \n",
      " 2   Gender          65796 non-null  int64         \n",
      " 3   Revenue_Total   65796 non-null  float64       \n",
      " 4   N_Purchases     65796 non-null  int64         \n",
      " 5   Purchase_DATE   65796 non-null  datetime64[ns]\n",
      " 6   Purchase_VALUE  65796 non-null  float64       \n",
      " 7   Pay_Method      65796 non-null  int64         \n",
      " 8   Time_Spent      65796 non-null  int64         \n",
      " 9   Browser         65796 non-null  int64         \n",
      " 10  Newsletter      65796 non-null  int64         \n",
      " 11  Voucher         65796 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(9)\n",
      "memory usage: 6.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Überprüfen der Datentypen\n",
    "print(df.info())\n",
    "\n",
    "# Konvertieren der Datentypen (Purchase_DATE)\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_to_date(date_str):\n",
    "  try:\n",
    "      # Versuch, das Datum zu konvertieren\n",
    "      return pd.to_datetime(date_str, format=\"%d.%m.%y\")\n",
    "  except ValueError:\n",
    "      # Wenn ein ValueError ausgelöst wird, ist das Datum nicht gültig\n",
    "      print(\"hi\")\n",
    "      return pd.NaT\n",
    "\n",
    "# Konvertieren des Datums in jeder Zeile\n",
    "df['Purchase_DATE'] = df['Purchase_DATE'].apply(convert_to_date)\n",
    "\n",
    "\n",
    "# Erneutes Überprüfen der Datentypen\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend wird der gesamte Datensatz überflogen, um ein grobes Verständnis für die Daten zu gewinnen. Hierfür wird der Datensatz angezeigt.\n",
    "\n",
    "Danach gilt es zu prüfen, ob es Null Werte oder Werte gibt, die auf einen Null- Wert hinweisen. Strings, welche die Zeichenkette \"N/A\" enthalten stehen oftmals für \"Not Available\", also Null- Werte.\n",
    "Wenn es mindestens einen \"N/A\" Wert gibt, wird der gesamte Datensatz bereinigt und durch geeignete statistische Mittel ersetzt. Die statitischen Mittel unterscheiden sich je nach Datentyp und Kontext der Variable.\n",
    "\n",
    "Trivialerweise ist Letzteres nicht von Nöten. Der Grund hierfür liegt darin, dass alle Spalten bereits die korrekten Datentypen besitzen. In diesem Fall haben wir keine Spalte mit Stringwerten, weshalb der Schritt übersprungen werden kann. \n",
    "Dennoch ist dies ein wichtiger Schritt, falls Daten mit Stringwerten im zukünftigen Verlauf des Projekts verwendet werden könnten. Dann muss dieser Schritt auf diese Werte angewendet werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_id       0\n",
      "Age               0\n",
      "Gender            0\n",
      "Revenue_Total     0\n",
      "N_Purchases       0\n",
      "Purchase_DATE     0\n",
      "Purchase_VALUE    0\n",
      "Pay_Method        0\n",
      "Time_Spent        0\n",
      "Browser           0\n",
      "Newsletter        0\n",
      "Voucher           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Anzeigen des Datensatzes\n",
    "df\n",
    "\n",
    "# Überprüfen Sie, ob Nullwerte im Datensatz vorhanden sind\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Überprüfen Sie, ob \"N/A\" im Datensatz vorhanden ist\n",
    "# print(df.apply(lambda x: x.str.contains('N/A', na=False).any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des Weiteren gilt es zu prüfen, ob sich in den Datensatz Outlier eingeschlichen haben. Outlier, auch Ausreißer genannt, sind Datenpunkte in einem Datensatz, die signifikant von den anderen Werten abweichen. Sie sind entweder extrem hoch oder extrem niedrig im Vergleich zu den umliegenden Werten. Diese extreme Abweichung kann das Gesamtergebnis statistischer Analysen beeinflussen und möglicherweise auf Fehler in den statistischen Verfahren hinweisen.\n",
    "\n",
    "df.quantile(0.25) und df.quantile(0.75): Diese Funktionen berechnen die ersten und dritten Quartile des Datensatzes. Quartile sind nützliche statistische Maße, die zur Erkennung von Outliers verwendet werden können.\n",
    "\n",
    "df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]: Diese Funktion erkennt und behandelt Outlier im Datensatz. Sie entfernt alle Zeilen, die als Outlier erkannt werden.\n",
    "\n",
    "\n",
    "\n",
    "Dieser Code wird von uns jedoch nicht verwendet. Denn es hat sich ergebeb, dass über 12000 Zeilen als Ausreißer identifiziert werden, was sehr unüblich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purchase_DATE Spalte in einen numerischen Datentyp umwandeln, um Ausreißer identifizieren zu können\n",
    "# df['Purchase_DATE'] = df['Purchase_DATE'].apply(lambda x: x.timestamp())\n",
    "\n",
    "\n",
    "# Erkennen von Outlier/ Ausreißer\n",
    "# Q1 = df.quantile(0.25)\n",
    "# Q3 = df.quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "\n",
    "# Behandeln von Outlier\n",
    "# df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuletzt betrachten wir die Minima und Maxima der verschiedenen Werte. Hier ist klar zu erkennen, dass keine Ausreißer vorhanden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min\n",
      "Customer_id                    504308\n",
      "Age                                16\n",
      "Gender                              0\n",
      "Revenue_Total                     0.5\n",
      "N_Purchases                         1\n",
      "Purchase_DATE     2021-01-01 00:00:00\n",
      "Purchase_VALUE                  0.005\n",
      "Pay_Method                          0\n",
      "Time_Spent                        120\n",
      "Browser                             0\n",
      "Newsletter                          0\n",
      "Voucher                             0\n",
      "dtype: object\n",
      "Max\n",
      "Customer_id                    570103\n",
      "Age                                63\n",
      "Gender                              1\n",
      "Revenue_Total                    59.9\n",
      "N_Purchases                         7\n",
      "Purchase_DATE     2022-01-01 00:00:00\n",
      "Purchase_VALUE                   59.9\n",
      "Pay_Method                          3\n",
      "Time_Spent                       1080\n",
      "Browser                             3\n",
      "Newsletter                          1\n",
      "Voucher                             1\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "min_values = df.min()\n",
    "max_values = df.max()\n",
    "print(\"Min\")\n",
    "print(min_values)\n",
    "print(\"Max\")\n",
    "print(max_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardisieren**\n",
    " \n",
    "Algorithmen gehen in der Regel davon aus, dass Variablen auf einer gleichen Skala sind. Dies entspricht jedoch nicht immer der Realität. Deshalb ist es notwendig die für die Analysen benötigten Variablen zu skalieren.\n",
    "Somit kann vermieden werden, das bestimmte Variablen einen überproportionalen Einfluss auf unser Modell haben.\n",
    "\n",
    "In diesem Fall verwenden wir die Standardisierung. Bei dieser Methode werden die Daten so skaliert, dass sie einen Durchschnittswert von 0 und einen Standardabweichung von 1 haben.\n",
    "\n",
    "Um zu vermeiden, dass Informationen aus den Testdaten in die Trainigsphase \"geleaked\" werden, sollten nur die Trainingsdaten skaliert werden. Das bedeutet, dass der Standardisierungsprozess von den Teammitgliedern aufgegriffen werden muss, da die Verteilung von Trainings- und Testdaten zufällig erfolgt.\n",
    "\n",
    "Es bleibt zu erwähnen, dass aus zeittechnischen Gründen und der parallelen Zusammenarbeit zu Folge nicht die Möglochkeit bestand die Daten für die einzelnen Modelle zugeschnitten zu bereinigen.\n",
    "\n",
    "Deshalb wird unten der allgemeine Ansatz beschrieben, den es für jedes unterschiedliche Modell zu verfeinern und zu implementieren gilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen eines StandardScaler-Objekts\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Definieren von Merkmalen und Zielvariablen\n",
    "features = ['Age', 'Revenue_Total', 'N_Purchases']\n",
    "merkmale = df[features]\n",
    "\n",
    "# Die Spalte, die predicted werden soll\n",
    "merkmale_y = df['Time_Spent']  \n",
    "\n",
    "# Instanziieren des StandardScaler-Objekts\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aufteilen des Datensatzes in Trainings- und Testdaten\n",
    "merkmale_train, merkmale_test, y_train, y_test = train_test_split(merkmale, merkmale_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fitten und transformieren des StandardScaler-Objekts mit den Trainingsdaten \n",
    "merkmale_train_scaled = scaler.fit_transform(merkmale_train)\n",
    "\n",
    "# Transformieren der Testdaten\n",
    "merkmale_test_scaled = scaler.transform(merkmale_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "## Ziel\n",
    "Schätzen, wie viel der Kunde insgesamt ausgibt. Daraus lässt sich ein Potenzial bei Kunden berechnen, bei denen die momentanen Ausgaben bekannt sind.\n",
    "\n",
    "## Schritte\n",
    "\n",
    "1. Datensatz laden und Imports\n",
    "2. Datenauswahl\n",
    "3. Aufteilen in Trainings-, Test- und Validierungsdaten (keine Crossvalidation, weil genug Daten vorhanden sind)\n",
    "4. Modelle mit dem Trainingsdatensatz berechnen \n",
    "5. Modellauswahl mittels der Validierungsdaten. Metrik: MQA\n",
    "6. Berechnung des Testfehlers. Metrik: MQA\n",
    "7. Anpassung des Modells\n",
    "8. Tree\n",
    "9. Auswahl des Modells\n",
    "10. Fazit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Datensatz laden und Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_id  Age  Gender  Revenue_Total  N_Purchases Purchase_DATE  \\\n",
      "0       504308   53       0           45.3            2    2021-06-22   \n",
      "1       504309   18       1           36.2            3    2021-12-10   \n",
      "2       504310   52       1           10.6            1    2021-03-14   \n",
      "3       504311   29       0           54.1            5    2021-10-25   \n",
      "4       504312   21       1           56.9            1    2021-09-14   \n",
      "\n",
      "   Purchase_VALUE  Pay_Method  Time_Spent  Browser  Newsletter  Voucher  \n",
      "0          24.915           1         885        0           0        0  \n",
      "1           2.896           2         656        0           0        1  \n",
      "2          10.600           0         761        0           1        0  \n",
      "3          43.280           1         906        0           1        0  \n",
      "4          56.900           1         605        0           1        0  \n",
      "27.732935132834818\n"
     ]
    }
   ],
   "source": [
    "data_reg = df\n",
    "\n",
    "df_reg = pd.DataFrame(data_reg)\n",
    "print(df_reg.head())\n",
    "durchschnitt_revenue = df_reg['Revenue_Total'].mean()\n",
    "print(durchschnitt_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Datenauswahl**\n",
    "\n",
    "Zuerst werden aus den qualitativen Daten, mit mehr als 2 Variablen, Dummyvariablen erzeugt. Trivialerweise sind Customer_id und Purchase_DATE davon ausgeschlossen.\n",
    "Danach versuchen wir die Inputmerkmale durch eine Korrelationsanalyse zu reduzieren. Ab einer Korrelation größer als 0,5 werden sich die Merkmale näher angeschaut.\n",
    "\n",
    "### Irrelevante Daten für die Korrelation:\n",
    "- Customer_id      -->> kein Merkmal für die Regression (Schlüssel zum User)\n",
    "- Purchase_DATE    -->> Qualitative Daten mit vielen Ausprägungen\n",
    "\n",
    "### Korrelationen:\n",
    "Browser_0 ~ Browser_1 -> -0.665166\n",
    "- Browser 0 und Browser 1 werden zum Interpretieren behalten.\n",
    "Jedoch wird die Variable Purchase_VALUE herausgenommen. Grund hierfür ist, dass die Variable den Wert des letzten Kaufes darstellt. Bei First-Time-Shoppern müsste dann dieser mit Revenue_Total übereinstimmen. Dies als auch die Varianz würden in diesem Beispiel das Ergebnis verfälschen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Age    Gender  N_Purchases  Purchase_VALUE  Time_Spent  \\\n",
      "Age             1.000000  0.001892    -0.005580        0.006416   -0.001506   \n",
      "Gender          0.001892  1.000000     0.001474       -0.002496    0.001595   \n",
      "N_Purchases    -0.005580  0.001474     1.000000       -0.219670    0.001604   \n",
      "Purchase_VALUE  0.006416 -0.002496    -0.219670        1.000000   -0.003069   \n",
      "Time_Spent     -0.001506  0.001595     0.001604       -0.003069    1.000000   \n",
      "Newsletter      0.003068 -0.001282    -0.001593        0.001272    0.003764   \n",
      "Voucher        -0.001288  0.001538    -0.004484       -0.000461    0.001487   \n",
      "Pay_Method_0   -0.000930  0.002142    -0.004805       -0.002288   -0.001751   \n",
      "Pay_Method_1   -0.001691  0.003402     0.000192        0.002956   -0.005369   \n",
      "Pay_Method_2    0.004828  0.002278     0.003334       -0.000126    0.004341   \n",
      "Pay_Method_3   -0.002062 -0.008886     0.001810       -0.000676    0.003716   \n",
      "Browser_0      -0.007451  0.000362    -0.007193        0.002906   -0.003711   \n",
      "Browser_1       0.004296 -0.002603     0.000281       -0.003946    0.003781   \n",
      "Browser_2       0.003853 -0.003393     0.002316       -0.003326    0.001052   \n",
      "Browser_3       0.003234  0.005172     0.009061        0.002934    0.000122   \n",
      "\n",
      "                Newsletter   Voucher  Pay_Method_0  Pay_Method_1  \\\n",
      "Age               0.003068 -0.001288     -0.000930     -0.001691   \n",
      "Gender           -0.001282  0.001538      0.002142      0.003402   \n",
      "N_Purchases      -0.001593 -0.004484     -0.004805      0.000192   \n",
      "Purchase_VALUE    0.001272 -0.000461     -0.002288      0.002956   \n",
      "Time_Spent        0.003764  0.001487     -0.001751     -0.005369   \n",
      "Newsletter        1.000000  0.004231     -0.001202     -0.000129   \n",
      "Voucher           0.004231  1.000000      0.005051      0.000260   \n",
      "Pay_Method_0     -0.001202  0.005051      1.000000     -0.418530   \n",
      "Pay_Method_1     -0.000129  0.000260     -0.418530      1.000000   \n",
      "Pay_Method_2     -0.002107  0.000887     -0.340484     -0.349037   \n",
      "Pay_Method_3      0.003780 -0.007103     -0.308161     -0.315902   \n",
      "Browser_0        -0.000409  0.003517     -0.000928     -0.001762   \n",
      "Browser_1        -0.003265 -0.005718      0.006370     -0.000542   \n",
      "Browser_2        -0.000388  0.001889      0.001058      0.003624   \n",
      "Browser_3         0.005082  0.000577     -0.007473      0.000842   \n",
      "\n",
      "                Pay_Method_2  Pay_Method_3  Browser_0  Browser_1  Browser_2  \\\n",
      "Age                 0.004828     -0.002062  -0.007451   0.004296   0.003853   \n",
      "Gender              0.002278     -0.008886   0.000362  -0.002603  -0.003393   \n",
      "N_Purchases         0.003334      0.001810  -0.007193   0.000281   0.002316   \n",
      "Purchase_VALUE     -0.000126     -0.000676   0.002906  -0.003946  -0.003326   \n",
      "Time_Spent          0.004341      0.003716  -0.003711   0.003781   0.001052   \n",
      "Newsletter         -0.002107      0.003780  -0.000409  -0.003265  -0.000388   \n",
      "Voucher             0.000887     -0.007103   0.003517  -0.005718   0.001889   \n",
      "Pay_Method_0       -0.340484     -0.308161  -0.000928   0.006370   0.001058   \n",
      "Pay_Method_1       -0.349037     -0.315902  -0.001762  -0.000542   0.003624   \n",
      "Pay_Method_2        1.000000     -0.256994   0.006464  -0.011346   0.002849   \n",
      "Pay_Method_3       -0.256994      1.000000  -0.003716   0.005283  -0.008495   \n",
      "Browser_0           0.006464     -0.003716   1.000000  -0.665166  -0.309790   \n",
      "Browser_1          -0.011346      0.005283  -0.665166   1.000000  -0.116166   \n",
      "Browser_2           0.002849     -0.008495  -0.309790  -0.116166   1.000000   \n",
      "Browser_3           0.002571      0.004952  -0.467157  -0.175176  -0.081585   \n",
      "\n",
      "                Browser_3  \n",
      "Age              0.003234  \n",
      "Gender           0.005172  \n",
      "N_Purchases      0.009061  \n",
      "Purchase_VALUE   0.002934  \n",
      "Time_Spent       0.000122  \n",
      "Newsletter       0.005082  \n",
      "Voucher          0.000577  \n",
      "Pay_Method_0    -0.007473  \n",
      "Pay_Method_1     0.000842  \n",
      "Pay_Method_2     0.002571  \n",
      "Pay_Method_3     0.004952  \n",
      "Browser_0       -0.467157  \n",
      "Browser_1       -0.175176  \n",
      "Browser_2       -0.081585  \n",
      "Browser_3        1.000000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>N_Purchases</th>\n",
       "      <th>Time_Spent</th>\n",
       "      <th>Newsletter</th>\n",
       "      <th>Voucher</th>\n",
       "      <th>Pay_Method_0</th>\n",
       "      <th>Pay_Method_1</th>\n",
       "      <th>Pay_Method_2</th>\n",
       "      <th>Pay_Method_3</th>\n",
       "      <th>Browser_0</th>\n",
       "      <th>Browser_1</th>\n",
       "      <th>Browser_2</th>\n",
       "      <th>Browser_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>-0.005580</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>-0.001288</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>-0.001691</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>-0.002062</td>\n",
       "      <td>-0.007451</td>\n",
       "      <td>0.004296</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.003234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.001892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>-0.001282</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>-0.008886</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>-0.002603</td>\n",
       "      <td>-0.003393</td>\n",
       "      <td>0.005172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Purchases</th>\n",
       "      <td>-0.005580</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>-0.001593</td>\n",
       "      <td>-0.004484</td>\n",
       "      <td>-0.004805</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>-0.007193</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.009061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time_Spent</th>\n",
       "      <td>-0.001506</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>-0.005369</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>-0.003711</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newsletter</th>\n",
       "      <td>0.003068</td>\n",
       "      <td>-0.001282</td>\n",
       "      <td>-0.001593</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.002107</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.003265</td>\n",
       "      <td>-0.000388</td>\n",
       "      <td>0.005082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voucher</th>\n",
       "      <td>-0.001288</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>-0.004484</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>-0.007103</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>-0.005718</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay_Method_0</th>\n",
       "      <td>-0.000930</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>-0.004805</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.418530</td>\n",
       "      <td>-0.340484</td>\n",
       "      <td>-0.308161</td>\n",
       "      <td>-0.000928</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>-0.007473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay_Method_1</th>\n",
       "      <td>-0.001691</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>-0.005369</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>-0.418530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.349037</td>\n",
       "      <td>-0.315902</td>\n",
       "      <td>-0.001762</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>0.000842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay_Method_2</th>\n",
       "      <td>0.004828</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>-0.002107</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>-0.340484</td>\n",
       "      <td>-0.349037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.256994</td>\n",
       "      <td>0.006464</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.002571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay_Method_3</th>\n",
       "      <td>-0.002062</td>\n",
       "      <td>-0.008886</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>-0.007103</td>\n",
       "      <td>-0.308161</td>\n",
       "      <td>-0.315902</td>\n",
       "      <td>-0.256994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003716</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>-0.008495</td>\n",
       "      <td>0.004952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Browser_0</th>\n",
       "      <td>-0.007451</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>-0.007193</td>\n",
       "      <td>-0.003711</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>-0.000928</td>\n",
       "      <td>-0.001762</td>\n",
       "      <td>0.006464</td>\n",
       "      <td>-0.003716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.665166</td>\n",
       "      <td>-0.309790</td>\n",
       "      <td>-0.467157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Browser_1</th>\n",
       "      <td>0.004296</td>\n",
       "      <td>-0.002603</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>-0.003265</td>\n",
       "      <td>-0.005718</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>-0.665166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.116166</td>\n",
       "      <td>-0.175176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Browser_2</th>\n",
       "      <td>0.003853</td>\n",
       "      <td>-0.003393</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>-0.000388</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>-0.008495</td>\n",
       "      <td>-0.309790</td>\n",
       "      <td>-0.116166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.081585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Browser_3</th>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.009061</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>-0.007473</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>-0.467157</td>\n",
       "      <td>-0.175176</td>\n",
       "      <td>-0.081585</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Age    Gender  N_Purchases  Time_Spent  Newsletter  \\\n",
       "Age           1.000000  0.001892    -0.005580   -0.001506    0.003068   \n",
       "Gender        0.001892  1.000000     0.001474    0.001595   -0.001282   \n",
       "N_Purchases  -0.005580  0.001474     1.000000    0.001604   -0.001593   \n",
       "Time_Spent   -0.001506  0.001595     0.001604    1.000000    0.003764   \n",
       "Newsletter    0.003068 -0.001282    -0.001593    0.003764    1.000000   \n",
       "Voucher      -0.001288  0.001538    -0.004484    0.001487    0.004231   \n",
       "Pay_Method_0 -0.000930  0.002142    -0.004805   -0.001751   -0.001202   \n",
       "Pay_Method_1 -0.001691  0.003402     0.000192   -0.005369   -0.000129   \n",
       "Pay_Method_2  0.004828  0.002278     0.003334    0.004341   -0.002107   \n",
       "Pay_Method_3 -0.002062 -0.008886     0.001810    0.003716    0.003780   \n",
       "Browser_0    -0.007451  0.000362    -0.007193   -0.003711   -0.000409   \n",
       "Browser_1     0.004296 -0.002603     0.000281    0.003781   -0.003265   \n",
       "Browser_2     0.003853 -0.003393     0.002316    0.001052   -0.000388   \n",
       "Browser_3     0.003234  0.005172     0.009061    0.000122    0.005082   \n",
       "\n",
       "               Voucher  Pay_Method_0  Pay_Method_1  Pay_Method_2  \\\n",
       "Age          -0.001288     -0.000930     -0.001691      0.004828   \n",
       "Gender        0.001538      0.002142      0.003402      0.002278   \n",
       "N_Purchases  -0.004484     -0.004805      0.000192      0.003334   \n",
       "Time_Spent    0.001487     -0.001751     -0.005369      0.004341   \n",
       "Newsletter    0.004231     -0.001202     -0.000129     -0.002107   \n",
       "Voucher       1.000000      0.005051      0.000260      0.000887   \n",
       "Pay_Method_0  0.005051      1.000000     -0.418530     -0.340484   \n",
       "Pay_Method_1  0.000260     -0.418530      1.000000     -0.349037   \n",
       "Pay_Method_2  0.000887     -0.340484     -0.349037      1.000000   \n",
       "Pay_Method_3 -0.007103     -0.308161     -0.315902     -0.256994   \n",
       "Browser_0     0.003517     -0.000928     -0.001762      0.006464   \n",
       "Browser_1    -0.005718      0.006370     -0.000542     -0.011346   \n",
       "Browser_2     0.001889      0.001058      0.003624      0.002849   \n",
       "Browser_3     0.000577     -0.007473      0.000842      0.002571   \n",
       "\n",
       "              Pay_Method_3  Browser_0  Browser_1  Browser_2  Browser_3  \n",
       "Age              -0.002062  -0.007451   0.004296   0.003853   0.003234  \n",
       "Gender           -0.008886   0.000362  -0.002603  -0.003393   0.005172  \n",
       "N_Purchases       0.001810  -0.007193   0.000281   0.002316   0.009061  \n",
       "Time_Spent        0.003716  -0.003711   0.003781   0.001052   0.000122  \n",
       "Newsletter        0.003780  -0.000409  -0.003265  -0.000388   0.005082  \n",
       "Voucher          -0.007103   0.003517  -0.005718   0.001889   0.000577  \n",
       "Pay_Method_0     -0.308161  -0.000928   0.006370   0.001058  -0.007473  \n",
       "Pay_Method_1     -0.315902  -0.001762  -0.000542   0.003624   0.000842  \n",
       "Pay_Method_2     -0.256994   0.006464  -0.011346   0.002849   0.002571  \n",
       "Pay_Method_3      1.000000  -0.003716   0.005283  -0.008495   0.004952  \n",
       "Browser_0        -0.003716   1.000000  -0.665166  -0.309790  -0.467157  \n",
       "Browser_1         0.005283  -0.665166   1.000000  -0.116166  -0.175176  \n",
       "Browser_2        -0.008495  -0.309790  -0.116166   1.000000  -0.081585  \n",
       "Browser_3         0.004952  -0.467157  -0.175176  -0.081585   1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy = pd.get_dummies(df_reg, columns=['Pay_Method', 'Browser'], prefix=['Pay_Method', 'Browser'])\n",
    "\n",
    "df_dummy = df_dummy.drop(columns=['Purchase_DATE', 'Customer_id','Revenue_Total'])\n",
    "\n",
    "print(df_dummy.corr())\n",
    "\n",
    "\n",
    "df_dummy = df_dummy.drop(columns=['Purchase_VALUE'])\n",
    "df_dummy.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Aufteilen in Trainings, Testdaten und Validierungsdaten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_x = df_dummy\n",
    "df_y = df_reg['Revenue_Total']\n",
    "\n",
    "\n",
    "df_x_train, df_x_rest, df_y_train, df_y_rest = train_test_split(df_x, df_y, test_size=0.3, random_state=42)\n",
    "df_x_test, df_x_validation, df_y_test, df_y_validation = train_test_split(df_x_rest, df_y_rest, test_size=0.5, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Modelle mit dem Trainingsdatensatz berechnen** + 5. **Modellauswahl mittels der Validierungsdaten. Metrik: MQA**\n",
    "\n",
    " \n",
    "Wir nehmen für die polynomiele Regression dem Grad 1. Somit haben wir zwar ein eher unflexibles Modell, jedoch können wir dadurch eine kleine Varianz erwarten. Was noch zu bemerken ist, ist das der Validierungsfehler sehr hoch ist, wenn man diesen mit dem durchschnittlichen Revenue_TOTAL von 27.73 vergleicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad: 1 Validation Error: 224.07202030371255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad: 2 Validation Error: 224.31831448215377\n",
      "Grad: 3 Validation Error: 224.92342883103103\n",
      "Grad: 4 Validation Error: 227.3738073618011\n"
     ]
    }
   ],
   "source": [
    "for degree in range(1, 5):\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    \n",
    "    df_x_train_poly = poly.fit_transform(df_x_train)\n",
    "    model = LinearRegression()\n",
    "\n",
    "    \n",
    "    model.fit(df_x_train_poly, df_y_train)\n",
    "\n",
    "    df_x_validation_poly = poly.transform(df_x_validation) # Validierungsdaten transformieren\n",
    "    y_pred_validation = model.predict(df_x_validation_poly) # Vorhersage erstellen (Validierungsdaten)\n",
    "    mse_validation = mean_squared_error(df_y_validation, y_pred_validation)\n",
    "    print(\"Grad: \"+str(degree)+\" Validation Error: \"+str(mse_validation))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Berechnung des Testfehlers. Metrik: MQA**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad: 1 Training Error: 222.53586403396156\n",
      "Grad: 1 Test Error: 225.6920692912952\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=1)\n",
    "df_x_train_poly = poly.fit_transform(df_x_train) # Daten transformieren\n",
    "\n",
    "model = LinearRegression() \n",
    "model.fit(df_x_train_poly, df_y_train) # Model erstellen\n",
    "df_x_test_poly = poly.transform(df_x_test) # Testdaten transformieren\n",
    "y_pred_train = model.predict(df_x_train_poly)\n",
    "y_pred_test = model.predict(df_x_test_poly) # Vorhersage erstellen (Testdaten)\n",
    "mse_train = mean_squared_error(df_y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(df_y_test, y_pred_test)\n",
    "print(\"Grad: \" + str(1) + \" Training Error: \" + str(mse_train))\n",
    "print(\"Grad: \"+str(1)+\" Test Error: \"+str(mse_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Anpassung des Modells**\n",
    " \n",
    "Der sehr hohe Trainings und Testfehler zeigt, dass wir einen hohen Bias und keine kleine Varianz haben. Die erste Intuition ist, dass wir ein flexibleres Modell brauchen, jedoch haben wir bereits ein Regressionen mit einem höheren Grad getestet, welche sogar schlechter ausgefallen sind. Dies ist der Grund weshalb wir nun Regressionsbäume testen.\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Tree**\n",
    " \n",
    "Der hohe Testfehler und sehr niedrieger Trainingsfehler, weist auf eine hohe Varianz und ein niedrigen Bias hin. Um die Varianz in diesem Baum zu reduzieren, kann dieser gestuzt werden. Infolge dessen erwatren wir aber auch einen höheren Bias, aufgrund des Bias-Varianz-Traidoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 54 : Training Error: 0.5364346353431617\n",
      "Tree 54 : Test Error: 458.7541118654372\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "regressor.fit(df_x_train, df_y_train)\n",
    "\n",
    "\n",
    "y_pred_train = regressor.predict(df_x_train)\n",
    "y_pred_test = regressor.predict(df_x_test)\n",
    "mse_train = mean_squared_error(df_y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(df_y_test, y_pred_test)\n",
    "print(\"Tree \"+str(regressor.get_depth())+\" : Training Error: \" + str(mse_train))\n",
    "print(\"Tree \"+str(regressor.get_depth())+\" : Test Error: \"+str(mse_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Auswahl des Modells**\n",
    "Leider weist kein Modell einen niedrigen Trainings- oder Validirungsfehler auf. Daher ist keines dieser Modelle geeignet, und es wird keines von ihnen genutzt. Dies ist auch der Grund, weshalb kein weiterer Testfehler errechnet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 1 : Training Error: 222.5672490728059\n",
      "Tree 1 : Validation Error: 223.99643288533161\n",
      "Tree 2 : Training Error: 222.5026897354644\n",
      "Tree 2 : Validation Error: 224.137159165071\n",
      "Tree 3 : Training Error: 222.40467181834563\n",
      "Tree 3 : Validation Error: 224.36882315386043\n",
      "Tree 4 : Training Error: 222.21154030797013\n",
      "Tree 4 : Validation Error: 224.74724495150969\n",
      "Tree 5 : Training Error: 221.8373056911736\n",
      "Tree 5 : Validation Error: 224.93825253584424\n",
      "Tree 6 : Training Error: 221.14349525802504\n",
      "Tree 6 : Validation Error: 225.93821056382117\n",
      "Tree 7 : Training Error: 219.98606998782506\n",
      "Tree 7 : Validation Error: 227.06418784782886\n",
      "Tree 8 : Training Error: 218.27199902042634\n",
      "Tree 8 : Validation Error: 228.17988389803304\n",
      "Tree 9 : Training Error: 215.67859726192472\n",
      "Tree 9 : Validation Error: 232.09111714513406\n",
      "Tree 10 : Training Error: 212.36332016089747\n",
      "Tree 10 : Validation Error: 234.98148448723694\n",
      "Tree 11 : Training Error: 207.64411715333657\n",
      "Tree 11 : Validation Error: 240.25882920655917\n",
      "Tree 12 : Training Error: 201.72418566420686\n",
      "Tree 12 : Validation Error: 247.57623524419688\n",
      "Tree 13 : Training Error: 194.4368352036253\n",
      "Tree 13 : Validation Error: 253.14847621857103\n",
      "Tree 14 : Training Error: 185.7583153958545\n",
      "Tree 14 : Validation Error: 260.594311780735\n",
      "Tree 15 : Training Error: 175.7751053434109\n",
      "Tree 15 : Validation Error: 272.56940479879205\n",
      "Tree 16 : Training Error: 164.3388024346449\n",
      "Tree 16 : Validation Error: 286.5698858821638\n",
      "Tree 17 : Training Error: 151.8371820526482\n",
      "Tree 17 : Validation Error: 300.29319327677416\n",
      "Tree 18 : Training Error: 138.48062825549002\n",
      "Tree 18 : Validation Error: 315.78721240915525\n",
      "Tree 19 : Training Error: 125.14342208946778\n",
      "Tree 19 : Validation Error: 331.18271308910715\n",
      "Tree 20 : Training Error: 112.31340946769382\n",
      "Tree 20 : Validation Error: 342.93569223131163\n",
      "Tree 21 : Training Error: 100.02342520448903\n",
      "Tree 21 : Validation Error: 357.5246977080972\n",
      "Tree 22 : Training Error: 88.42158886370046\n",
      "Tree 22 : Validation Error: 369.030937433176\n",
      "Tree 23 : Training Error: 77.33444110767512\n",
      "Tree 23 : Validation Error: 381.25292077142416\n",
      "Tree 24 : Training Error: 67.03842127326213\n",
      "Tree 24 : Validation Error: 393.48088123748056\n",
      "Tree 25 : Training Error: 57.4107421445734\n",
      "Tree 25 : Validation Error: 405.1687821148096\n",
      "Tree 26 : Training Error: 48.52222989647275\n",
      "Tree 26 : Validation Error: 417.72795058664946\n",
      "Tree 27 : Training Error: 40.867706734594115\n",
      "Tree 27 : Validation Error: 425.005187833317\n",
      "Tree 28 : Training Error: 33.61838427369728\n",
      "Tree 28 : Validation Error: 434.2343239807023\n",
      "Tree 29 : Training Error: 27.475218251654436\n",
      "Tree 29 : Validation Error: 445.0673948571599\n",
      "Tree 30 : Training Error: 22.403183783630915\n",
      "Tree 30 : Validation Error: 447.16057214726794\n",
      "Tree 31 : Training Error: 18.1191288882543\n",
      "Tree 31 : Validation Error: 451.6293775642659\n",
      "Tree 32 : Training Error: 14.46720945421959\n",
      "Tree 32 : Validation Error: 457.08168214324996\n",
      "Tree 33 : Training Error: 11.766879866254033\n",
      "Tree 33 : Validation Error: 459.3606092154825\n",
      "Tree 34 : Training Error: 9.510483306048286\n",
      "Tree 34 : Validation Error: 462.1838107549805\n",
      "Tree 35 : Training Error: 7.613576384289578\n",
      "Tree 35 : Validation Error: 462.3174691113062\n",
      "Tree 36 : Training Error: 6.085057244952001\n",
      "Tree 36 : Validation Error: 464.6724836688986\n",
      "Tree 37 : Training Error: 4.889089151197433\n",
      "Tree 37 : Validation Error: 464.8791864853226\n",
      "Tree 38 : Training Error: 3.885098166974351\n",
      "Tree 38 : Validation Error: 465.86473675431694\n",
      "Tree 39 : Training Error: 2.8969536008999976\n",
      "Tree 39 : Validation Error: 466.14029566535874\n",
      "Tree 40 : Training Error: 2.13004840141881\n",
      "Tree 40 : Validation Error: 468.34260922024873\n",
      "Tree 41 : Training Error: 1.549825433336121\n",
      "Tree 41 : Validation Error: 471.3252111532063\n",
      "Tree 42 : Training Error: 1.16485699237748\n",
      "Tree 42 : Validation Error: 471.89017750229317\n",
      "Tree 43 : Training Error: 0.9185915384387557\n",
      "Tree 43 : Validation Error: 474.38680157564033\n",
      "Tree 44 : Training Error: 0.752432071594515\n",
      "Tree 44 : Validation Error: 472.19754785130664\n",
      "Tree 45 : Training Error: 0.6744324622250344\n",
      "Tree 45 : Validation Error: 472.36225128101444\n",
      "Tree 46 : Training Error: 0.6084134122783513\n",
      "Tree 46 : Validation Error: 473.3958398800393\n",
      "Tree 47 : Training Error: 0.5682282823457889\n",
      "Tree 47 : Validation Error: 474.0001677361252\n",
      "Tree 48 : Training Error: 0.5454729586285593\n",
      "Tree 48 : Validation Error: 472.0005360621724\n",
      "Tree 49 : Training Error: 0.5431727920992311\n",
      "Tree 49 : Validation Error: 471.96250935632605\n",
      "Tree 50 : Training Error: 0.5395532347598265\n",
      "Tree 50 : Validation Error: 471.9344891084093\n",
      "Tree 51 : Training Error: 0.5370848730920381\n",
      "Tree 51 : Validation Error: 471.07015273556226\n",
      "Tree 52 : Training Error: 0.5366397435062351\n",
      "Tree 52 : Validation Error: 471.64579685916914\n",
      "Tree 53 : Training Error: 0.5365528584145732\n",
      "Tree 53 : Validation Error: 471.1569308510638\n"
     ]
    }
   ],
   "source": [
    "for max_depth in range(1, 54):\n",
    "    regressor = DecisionTreeRegressor(max_depth=max_depth,random_state=42)\n",
    "    regressor.fit(df_x_train, df_y_train)\n",
    "\n",
    "\n",
    "    y_pred_train = regressor.predict(df_x_train)\n",
    "    y_pred_validation = regressor.predict(df_x_validation)\n",
    "    mse_train = mean_squared_error(df_y_train, y_pred_train)\n",
    "    mse_validation = mean_squared_error(df_y_validation, y_pred_validation)\n",
    "    print(\"Tree \"+str(regressor.get_depth())+\" : Training Error: \" + str(mse_train))\n",
    "    print(\"Tree \"+str(regressor.get_depth())+\" : Validation Error: \"+str(mse_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **Fazit**\n",
    "\n",
    "Leider ist es uns nicht gelungen, ein Modell zu erstellen, das den geschätzten Gesamtumsatz liefert. Ein Grund dafür könnte die Datenmenge sein, obwohl wir bereits etwa 60.000 Datensätze haben. Ein weiterer Grund könnte sein, dass es keinen klaren Zusammenhang zwischen dem Gesamtumsatz und den restlichen Merkmalen gibt, weshalb wir kein passendes Modell erstellen können.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression\n",
    "\n",
    "In diesem Abschnitt werden wir eine logitische Regression vornehmen. Das Ziel ist es neue Kunden als Groß- oder Klein-Kunde klassifizieren zu können.\n",
    "Dadurch können Großkunden spezifischer Angebote erhalten. Ein weitere Aspekt wäre die Maximierung des Umsatzes jedes Kunden, wodurch Klein-Kunden im Laufe der Zeit zum Groß-Kunden heranwachsen.\n",
    "\n",
    "Die Kunden werden als Groß-Kunde klassifiziert wenn ihr durchschnittlicher Umsatz über dem Median liegt und sie mehr als 3 Einkäufe getätigt haben.\n",
    "Alle anderen Kunden werden als Klein-Kunden klassifiziert.\n",
    "Hierfür haben wir dem Datensatz eine weitere Spalte als dummy_variable = Großkunde hinzugefügt.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Age    Gender  Revenue_Total  N_Purchases  \\\n",
      "Age             1.000000  0.001892       0.000091    -0.005580   \n",
      "Gender          0.001892  1.000000      -0.001006     0.001474   \n",
      "Revenue_Total   0.000091 -0.001006       1.000000     0.005794   \n",
      "N_Purchases    -0.005580  0.001474       0.005794     1.000000   \n",
      "Purchase_VALUE  0.006416 -0.002496       0.649235    -0.219670   \n",
      "Pay_Method      0.000750 -0.006452       0.005789     0.004603   \n",
      "Time_Spent     -0.001506  0.001595      -0.003520     0.001604   \n",
      "Newsletter      0.003068 -0.001282       0.003578    -0.001593   \n",
      "Voucher        -0.001288  0.001538       0.000071    -0.004484   \n",
      "\n",
      "                Purchase_VALUE  Pay_Method  Time_Spent  Newsletter   Voucher  \n",
      "Age                   0.006416    0.000750   -0.001506    0.003068 -0.001288  \n",
      "Gender               -0.002496   -0.006452    0.001595   -0.001282  0.001538  \n",
      "Revenue_Total         0.649235    0.005789   -0.003520    0.003578  0.000071  \n",
      "N_Purchases          -0.219670    0.004603    0.001604   -0.001593 -0.004484  \n",
      "Purchase_VALUE        1.000000    0.000422   -0.003069    0.001272 -0.000461  \n",
      "Pay_Method            0.000422    1.000000    0.005087    0.002430 -0.006916  \n",
      "Time_Spent           -0.003069    0.005087    1.000000    0.003764  0.001487  \n",
      "Newsletter            0.001272    0.002430    0.003764    1.000000  0.004231  \n",
      "Voucher              -0.000461   -0.006916    0.001487    0.004231  1.000000  \n"
     ]
    }
   ],
   "source": [
    "data_log = df\n",
    "data_log.head()\n",
    "\n",
    "df_log = pd.DataFrame(data_log)\n",
    "\n",
    "df_log = df_log.drop(columns=['Browser', 'Purchase_DATE', 'Customer_id'])\n",
    "\n",
    "# Korrelationsmatrix aufstellen\n",
    "print(df_log.corr())\n",
    "\n",
    "# Korrelation zwischen \"Revenue_Total\" und \"Purchase_Value\"\n",
    "df_log = df_log.drop(columns=['Purchase_VALUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Revenue_Total</th>\n",
       "      <th>N_Purchases</th>\n",
       "      <th>Pay_Method</th>\n",
       "      <th>Time_Spent</th>\n",
       "      <th>Newsletter</th>\n",
       "      <th>Voucher</th>\n",
       "      <th>Großkunde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>36.2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>656</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>761</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>54.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Revenue_Total  N_Purchases  Pay_Method  Time_Spent  \\\n",
       "0   53       0           45.3            2           1         885   \n",
       "1   18       1           36.2            3           2         656   \n",
       "2   52       1           10.6            1           0         761   \n",
       "3   29       0           54.1            5           1         906   \n",
       "4   21       1           56.9            1           1         605   \n",
       "\n",
       "   Newsletter  Voucher  Großkunde  \n",
       "0           0        0          0  \n",
       "1           0        1          0  \n",
       "2           1        0          0  \n",
       "3           1        0          1  \n",
       "4           1        0          0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hinzufügen einer neuen Spalte (Großkunde 0/1)\n",
    "median_revenue = df_log['Revenue_Total'].median()\n",
    "df_log['Großkunde'] = np.where((df_log['Revenue_Total'] > median_revenue) & (df_log['N_Purchases'] > 3), 1,0) \n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Daten sind nun bereinigt und bereit für die logistische Regression.\n",
    "Wir haben Daten mit kaum, bis gar keinen Einfluss auf unsere Output Variable Großkunde entfernt.\n",
    "Dies geschah über die Korellationsmatrix.\n",
    "Außerdem haben wir die dummy_variable dem Datensatz hinzugefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 0.88\n",
      "[[4373  348]\n",
      " [ 427 1432]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Aufteilen Input- und Output-Variablen\n",
    "\n",
    "inputvar = df_log.drop(columns=['Großkunde'])\n",
    "outputvar = df_log['Großkunde']\n",
    "\n",
    "# Aufteilung in Trainings- und Testdaten\n",
    "\n",
    "inputvar_train, inputvar_test, outputvar_train, outputvar_test = train_test_split(inputvar, outputvar, test_size=0.1, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(inputvar_train, outputvar_train)\n",
    "\n",
    "output_prediction = logreg.predict(inputvar_test)\n",
    "genauigkeit = accuracy_score(outputvar_test, output_prediction)\n",
    "print(f'Genauigkeit: {genauigkeit:.2f}')\n",
    "\n",
    "confusion = confusion_matrix(outputvar_test, output_prediction)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell ist mit 88% Genauigkeit effizient.\n",
    "Es ist jedoch zu beachten, dass die dummy_Variable auf Grundlage unserer Definition berechnet wurde. \n",
    "Somit ist der Zusammenhang zwischen den Input-Variablen und der Output-Variable klar. \n",
    "Dennoch soll das Modell bei zukünftig großen Datensetzen eine valide Klassifikation vornehmen. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
